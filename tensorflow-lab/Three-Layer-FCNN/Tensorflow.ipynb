{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three layer Fully Connected Neural Network in Tensorflow\n",
    "Tensorflow, like Pytorch, has two approaches to creating a basic deep learning netwokrk. The **Sequential API** is very similar to the Pytorch **Sequential** class. The layers can be added using the **Sequential API** with individual calls to `add()` but the structure is clearer if all the layers are assembled in a List. The TF.Keras class used for full connected neural networks is *Dense*. Each node in a layer has an activation function.  The most commonly used function is the [rectified linear unit](https://en.wikipedia.org/wiki/Rectifier_(neural_networks)) (ReLU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, ReLU\n",
    "\n",
    "sequential_model = Sequential([\n",
    "    Dense(10, input_shape=(13,), activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 10)                140       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 261\n",
      "Trainable params: 261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sequential_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same network can be built with the **Functional API** by creating objects that are themselves callable.  The sytax here is `Object(constructor params)(functional params)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "inputs = Input((13,))\n",
    "input = Dense(10, activation='relu')(inputs)\n",
    "hidden = Dense(10, activation='relu')(input)\n",
    "output = Dense(1)(hidden)\n",
    "functional_model = Model(inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 13)]              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                140       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 261\n",
      "Trainable params: 261\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "functional_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *imagined* problem addressed by this network is predicting a home sale price given 13 factors.  The network would be trained using how much it missed the real world result.  The difference between the network prediction and the actual result is termed the error. The errors are collected and summarized by a **loss function**. This network will use [Mean Square Error](https://www.youtube.com/watch?v=uD1Dfz0aqkA) as a loss function.  The value from the loss function is then used by an optimizer function to calculate how the weights on each connection should be adjusted. Here we will use [Root Mean Square Error](https://www.youtube.com/watch?v=ng629LziKrQ) as the **optimizer function**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "functional_model.compile(loss='mse', optimizer='rmsprop')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-lab",
   "language": "python",
   "name": "tensorflow-lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
